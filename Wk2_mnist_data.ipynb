{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wk2-mnist-data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dslans/coursera-ai/blob/master/Wk2_mnist_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33Gv45qgMA2C",
        "colab_type": "text"
      },
      "source": [
        "# Predictions Using the MNIST data set\n",
        "Predicting articles of clothing using Neural Network Framework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf_c6_6UMOJJ",
        "colab_type": "text"
      },
      "source": [
        "## Importing Tensorflow and Fashion MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GirICVmAMUGB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6225b436-2ec9-48f0-bbbb-e7171aa1d49c"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-FnySiPMZzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kItArVCMdoh",
        "colab_type": "text"
      },
      "source": [
        "Using load_data will give training and testing values and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz7B85hyMi9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-ljt6ScMuLC",
        "colab_type": "text"
      },
      "source": [
        "Viewing the Images to see what the data looks like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuEvzlRkM3hm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b199e925-cbd7-47e5-86f3-8c24f31186a7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(training_images[0])\n",
        "print(training_labels[0])\n",
        "print(training_images[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0\n",
            "    0   1   4   0   0   0   0   1   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62\n",
            "   54   0   0   0   1   3   4   0   0   3]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134\n",
            "  144 123  23   0   0   0   0  12  10   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178\n",
            "  107 156 161 109  64  23  77 130  72  15]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216\n",
            "  216 163 127 121 122 146 141  88 172  66]\n",
            " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229\n",
            "  223 223 215 213 164 127 123 196 229   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228\n",
            "  235 227 224 222 224 221 223 245 173   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198\n",
            "  180 212 210 211 213 223 220 243 202   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192\n",
            "  169 227 208 218 224 212 226 197 209  52]\n",
            " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203\n",
            "  198 221 215 213 222 220 245 119 167  56]\n",
            " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240\n",
            "  232 213 218 223 234 217 217 209  92   0]\n",
            " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219\n",
            "  222 221 216 223 229 215 218 255  77   0]\n",
            " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208\n",
            "  211 218 224 223 219 215 224 244 159   0]\n",
            " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230\n",
            "  224 234 176 188 250 248 233 238 215   0]\n",
            " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223\n",
            "  255 255 221 234 221 211 220 232 246   0]\n",
            " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221\n",
            "  188 154 191 210 204 209 222 228 225   0]\n",
            " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117\n",
            "  168 219 221 215 217 223 223 224 229  29]\n",
            " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245\n",
            "  239 223 218 212 209 222 220 221 230  67]\n",
            " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216\n",
            "  199 206 186 181 177 172 181 205 206 115]\n",
            " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191\n",
            "  195 191 198 192 176 156 167 177 210  92]\n",
            " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209\n",
            "  210 210 211 188 188 194 192 216 170   0]\n",
            " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179\n",
            "  182 182 181 176 166 168  99  58   0   0]\n",
            " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFE1JREFUeJzt3WtwlFWaB/D/053OhdABAhgQM4KK\nF0ZXdCJ4K8cRdZCyFh1nLS3LxSprsHZ1amfWD1rObK37ZcuyVi1r3Z3ZqKy4NTqzUyMlY1GOGlcZ\nbwwRGVFYRCEKCEkgkoQknfTl2Q95dQPmPG/T3em38fx/VRSdfvqkT7rzz9vd5z3niKqCiPwTi7oD\nRBQNhp/IUww/kacYfiJPMfxEnmL4iTzF8BN5iuEn8hTDT+SpqnLeWbXUaC3qy3mXRF5JYQAjOiz5\n3Lao8IvIUgCPAogDeEJVH7BuX4t6LJYlxdwlERk2aFvety34Zb+IxAH8G4BrACwAcLOILCj0+xFR\neRXznn8RgI9VdaeqjgD4NYDlpekWEU20YsI/B8DuMV/vCa47goisFJF2EWlPY7iIuyOiUprwT/tV\ntVVVW1S1JYGaib47IspTMeHfC6B5zNcnBdcR0XGgmPBvBDBfROaJSDWAmwCsLU23iGiiFTzUp6oZ\nEbkLwB8wOtS3SlU/LFnPiGhCFTXOr6rrAKwrUV+IqIx4ei+Rpxh+Ik8x/ESeYviJPMXwE3mK4Sfy\nFMNP5CmGn8hTDD+Rpxh+Ik8x/ESeYviJPMXwE3mqrEt3UwQkZBVn1aK+fXx6o1n/4vunO2sNz7xT\n1H2H/WxSlXDWND1S3H0XK+x5sRT5nH2JR34iTzH8RJ5i+Ik8xfATeYrhJ/IUw0/kKYafyFMc5/+G\nk3jcrGsmY9ZjC+29V7fdMdluP+SuJQYWmW2rhnJmPfFSu1kvaiw/7ByCkMcVYh9Xi+mbVBmxtZ/O\nI/DIT+Qphp/IUww/kacYfiJPMfxEnmL4iTzF8BN5qqhxfhHpANAPIAsgo6otpegUlY45Jozwcf7d\n359q1m+56I9m/c3uU5y1T2tmmW21ziyj6sqLzPrp/77XWct0fGZ/85A582GPW5j4tGnuYjZrts32\n9bmLxzDVvxQn+XxPVQ+U4PsQURnxZT+Rp4oNvwJ4SUTeFZGVpegQEZVHsS/7L1XVvSJyAoCXReR/\nVXX92BsEfxRWAkAtJhV5d0RUKkUd+VV1b/B/F4A1AL42U0NVW1W1RVVbEqgp5u6IqIQKDr+I1ItI\n8svLAK4G8EGpOkZEE6uYl/1NANbI6NTHKgDPqOqLJekVEU24gsOvqjsBnFvCvtAEyKVSRbUfOe+w\nWf/hFHtOfW0s7ay9HrPn6+99tdmsZ//C7tunDyedtdx7F5ttp39gj7U3vLfPrB+4bI5Z7/6Oe0C+\nKWQ7g2mvfOKsSU/+keZQH5GnGH4iTzH8RJ5i+Ik8xfATeYrhJ/KUaIm2+81HgzTqYllStvvzhrXM\ndMjze/jGC836NT9/zayfVfu5We/P1TprI1rc2eWPbf+uWR/YOcVZi42EbJEdUs422Utva9o+rk7b\n5P7Z65Z3mm3l8ZnO2vttj+Jwz+689v/mkZ/IUww/kacYfiJPMfxEnmL4iTzF8BN5iuEn8hTH+StB\nyHbQRQl5fs9+1/77/4Np9pTdMHFjLekBrTbbHsrWF3Xf3Rn3lN50yDkGT+ywp/weNs4hAIBYxn5O\nr/ree87aDY0bzbYPnnqOs7ZB29CnPRznJyI3hp/IUww/kacYfiJPMfxEnmL4iTzF8BN5qhS79FKx\nyniuxdF2HD7BrB9smGzW92fsLbynx93LaydjQ2bbuQl78+furHscHwDiCffS4CMaN9v+07d/b9ZT\nZyXMekLspb8vNtZB+Kutf222rcdOs54vHvmJPMXwE3mK4SfyFMNP5CmGn8hTDD+Rpxh+Ik+FjvOL\nyCoA1wLoUtWzg+saAfwGwFwAHQBuVNUvJq6bNFFm1tjbXNeKe4ttAKiWjFn/PD3NWdsxdIbZ9qM+\n+xyEpU0fmvW0MZZvrTMAhI/Tn5iwf91Tap8HYD2qlzTZ4/ibzWr+8jnyPwVg6VHX3QugTVXnA2gL\nviai40ho+FV1PYCeo65eDmB1cHk1gOtK3C8immCFvudvUtV9weX9AJpK1B8iKpOiP/DT0UUAnW+g\nRGSliLSLSHsaw8XeHRGVSKHh7xSR2QAQ/N/luqGqtqpqi6q2JFBT4N0RUakVGv61AFYEl1cAeL40\n3SGicgkNv4g8C+BtAGeIyB4RuR3AAwCuEpEdAK4Mviai40joOL+q3uwocQH+UglZt1/i9txzzbjH\n2uPT3OPsAPDdqVvMene2wawfyk4y61Pjg85af6bWbNszZH/vM2v2mfVNg3OdtZnV9ji91W8A6BiZ\nYdbn1+w36w92uuPTXHv04NqRMksuc9Z0w9tm27F4hh+Rpxh+Ik8x/ESeYviJPMXwE3mK4SfyFJfu\nrgQhS3dLlf00WUN9u28/y2x7xSR7ieq3UnPM+syqfrNuTaudXdNrtk02pcx62DBjY5V7unJ/ts5s\nOylmn4oe9nOfX20vO/7TV8531pJnHzTbNiSMY/Yx7PbOIz+Rpxh+Ik8x/ESeYviJPMXwE3mK4Sfy\nFMNP5CmO81cASVSb9VzKHu+2zNgyYtYPZO0lpqfG7Kmt1SFLXFtbYV/cuMts2x0yFr9paJ5ZT8bd\nW4DPjNnj9M0Je6x9S6rZrK8bOM2s337tK87as61XmW2rX3zLWRO1n6+xeOQn8hTDT+Qphp/IUww/\nkacYfiJPMfxEnmL4iTx1fI3zG0tcS5U9Xi3xkL9zMbueSxnzu3P2WHcYTdtj8cV49D8eM+u7M1PN\n+v60XQ9b4jprTDB/Z2iK2bY2Zm8PPrOqz6z35ezzBCz9OXtZcWudAiC87/dM3+GsPdd7pdm2VHjk\nJ/IUw0/kKYafyFMMP5GnGH4iTzH8RJ5i+Ik8FTrOLyKrAFwLoEtVzw6uux/AjwB0Bze7T1XXFduZ\nYtanDxsrV3vYNVJDyxeZ9d3X2ecR3HLen5y1/Zmk2fY9YxtrAJhizIkHgPqQ9e1T6j7/4vMRe/vw\nsLFya11+ADjBOA8gq/Zxb2/a7luYsPMf9mSMPQX+0l5rYOrTBXXpa/I58j8FYOk41z+iqguDf0UH\nn4jKKzT8qroeQE8Z+kJEZVTMe/67ROR9EVklIsW9RiKisis0/L8AcCqAhQD2AXjIdUMRWSki7SLS\nnob9/pCIyqeg8Ktqp6pmVTUH4HEAzk+sVLVVVVtUtSWBmkL7SUQlVlD4RWT2mC+vB/BBabpDROWS\nz1DfswAuBzBDRPYA+EcAl4vIQgAKoAPAHRPYRyKaAKIhe8OXUoM06mJZUrb7G6tq9iyznp7XZNZ7\nznLvBT84y94UfeGybWb9tqY3zHp3tsGsJ8R9/kPYPvSzEofM+qu9C8z65Cr7cxzrPIHz6zrMtody\n7sccAE6s+sKs3/PxD521pkn2WPoTJ9uj12nNmfXtafstbjLmPi/lj4P2mv9rFsx01jZoG/q0x/6F\nDPAMPyJPMfxEnmL4iTzF8BN5iuEn8hTDT+Spilq6e/iaC8z6CT/b6awtbNhjtl1QZw+npXL20t/W\n9NKtQ3PMtoM5ewvuHSP2MGRvxh7yiot72KlrxJ7S+9Aue5notkW/NOs//3y8CZ//L1bnHko+mJ1s\ntr1hsr00N2A/Z3d8a72zdkp1l9n2hYHZZv3zkCm/TYlesz430e2s/SD5kdl2DdxDfceCR34iTzH8\nRJ5i+Ik8xfATeYrhJ/IUw0/kKYafyFPlHecXe3nuxf+80Wy+JPmhszao9hTKsHH8sHFby5Qqe5nm\n4bT9MHel7Sm7YU6v2e+sXd+w2Wy7/rHFZv3S1I/N+idX/KdZbxtyb2XdnbF/7pt2XWHWN33WbNYv\nnLvLWTsnuddsG3ZuRTKeMuvWNGsAGMi5f1/fSdnnP5QKj/xEnmL4iTzF8BN5iuEn8hTDT+Qphp/I\nUww/kafKunR33axmPfXWv3fWW+/8V7P9Mz0XOmvNtfZeoidXHzDr0+P2ds+WZMwe8z0jYY/5vjBw\nkll/7dCZZv07yQ5nLSH29t6XT/rYrN/207vNeqbWXiW6b677+JKpt3/3Gs49aNZ/fNqrZr3a+NkP\nZe1x/LDHLWwL7jDWGgzJmL0t+kPLrnfW3u54Cr1D+7h0NxG5MfxEnmL4iTzF8BN5iuEn8hTDT+Qp\nhp/IU6Hz+UWkGcDTAJoAKIBWVX1URBoB/AbAXAAdAG5UVXPP5FgamNTpHt98oW+h2ZdT6txrnR9I\n2+vT/+HwOWb9pDp7u2drq+nTjPn0ALA5NdWsv9j9bbN+Yp29fn1neoqzdjBdb7YdNOaVA8CTjzxs\n1h/qtNf9v75xk7N2brU9jn8oZx+btobsd9Cfq3XWUmqv79Abch5A0vh9AIC02tGKG1t8T43Z5xD0\nnTPdWct25r9ERz5H/gyAu1V1AYALAdwpIgsA3AugTVXnA2gLviai40Ro+FV1n6puCi73A9gGYA6A\n5QBWBzdbDeC6ieokEZXeMb3nF5G5AM4DsAFAk6ruC0r7Mfq2gIiOE3mHX0QmA/gdgJ+o6hFvQnV0\ngsC4J2qLyEoRaReR9szwQFGdJaLSySv8IpLAaPB/parPBVd3isjsoD4bwLg7H6pqq6q2qGpLVY39\n4RMRlU9o+EVEADwJYJuqjv3ody2AFcHlFQCeL333iGii5DMucAmAWwFsEZEv14G+D8ADAP5bRG4H\n8CmAG8O+UXwkh+TuYWc9p/ZMxFcPuKe2NtX2m20XJneb9e2D9rDRlqETnbVNVd8y29bF3dt7A8CU\nantKcH2V+zEDgBkJ988+r8beitqa9goAG1P2z/Y3M18z659l3Eui/37gdLPt1kH3Yw4A00KWTN/S\n524/mLG3TR/O2tFIZeyh4yk19nN6QeOnztp22NuDd59rTJN+02x6hNDwq+obAFypXJL/XRFRJeEZ\nfkSeYviJPMXwE3mK4SfyFMNP5CmGn8hT5d2i+/AQYq+/5yz/9qVLzOb/sPy3ztrrIctbv7DfHpft\nG7Gnts6c5D41ucEYZweAxoR9WnPYFt+1Ids9f5Fxnzk5HLOnrmado7ij9g+7pwsDwJu5+WY9nXNv\n0T1s1IDw8yN6RmaY9RPrep21/ox7ui8AdPQ3mvUDvfY22qlJdrTeyJ7qrC2d5d6KHgDqutzPWcz+\nVTnytvnflIi+SRh+Ik8x/ESeYviJPMXwE3mK4SfyFMNP5KmybtHdII26WAqfBdx7i3uL7lP+drvZ\ndtHUXWZ9U589b/0zY9w3HbLEdCLmXqYZACYlRsx6bch4d3XcPSc/Nv7qal/JhYzz18ftvoWtNdBQ\n5Z7Xnozbc95jxjbW+YgbP/ufeucW9b2TIT93Ru3fiYumfOKsrdp1sdl2yjL3tuobtA192sMtuonI\njeEn8hTDT+Qphp/IUww/kacYfiJPMfxEnir/OH/8avcNcvYa8sUYuGGxWV9830a7nnSPy55Z3Wm2\nTcAer64NGc+uj9nDtinjOQz76/7GULNZz4Z8h1e/OMusp43x7s7BBrNtwjh/IR/WPhBDmZAtuofs\n+f7xmJ2b1Gv2WgPTt7rP3ahZZ/8uWjjOT0ShGH4iTzH8RJ5i+Ik8xfATeYrhJ/IUw0/kqdBxfhFp\nBvA0gCYACqBVVR8VkfsB/AhAd3DT+1R1nfW9ip3PX6nkAntPgKFZdWa95qA9N7z/ZLt9wyfufQFi\nw/ZC7rk/bzPrdHw5lnH+fDbtyAC4W1U3iUgSwLsi8nJQe0RV/6XQjhJRdELDr6r7AOwLLveLyDYA\ncya6Y0Q0sY7pPb+IzAVwHoANwVV3icj7IrJKRKY52qwUkXYRaU/DfnlLROWTd/hFZDKA3wH4iar2\nAfgFgFMBLMToK4OHxmunqq2q2qKqLQnY++ERUfnkFX4RSWA0+L9S1ecAQFU7VTWrqjkAjwNYNHHd\nJKJSCw2/iAiAJwFsU9WHx1w/e8zNrgfwQem7R0QTJZ9P+y8BcCuALSKyObjuPgA3i8hCjA7/dQC4\nY0J6eBzQjVvMuj05NFzDW4W3LW7xa/omy+fT/jeAcRd3N8f0iaiy8Qw/Ik8x/ESeYviJPMXwE3mK\n4SfyFMNP5CmGn8hTDD+Rpxh+Ik8x/ESeYviJPMXwE3mK4SfyFMNP5KmybtEtIt0APh1z1QwAB8rW\ngWNTqX2r1H4B7FuhStm3k1V1Zj43LGv4v3bnIu2q2hJZBwyV2rdK7RfAvhUqqr7xZT+Rpxh+Ik9F\nHf7WiO/fUql9q9R+AexboSLpW6Tv+YkoOlEf+YkoIpGEX0SWish2EflYRO6Nog8uItIhIltEZLOI\ntEfcl1Ui0iUiH4y5rlFEXhaRHcH/426TFlHf7heRvcFjt1lElkXUt2YR+R8R2SoiH4rI3wXXR/rY\nGf2K5HEr+8t+EYkD+AjAVQD2ANgI4GZV3VrWjjiISAeAFlWNfExYRC4DcBjA06p6dnDdgwB6VPWB\n4A/nNFW9p0L6dj+Aw1Hv3BxsKDN77M7SAK4DcBsifOyMft2ICB63KI78iwB8rKo7VXUEwK8BLI+g\nHxVPVdcD6Dnq6uUAVgeXV2P0l6fsHH2rCKq6T1U3BZf7AXy5s3Skj53Rr0hEEf45AHaP+XoPKmvL\nbwXwkoi8KyIro+7MOJqCbdMBYD+Apig7M47QnZvL6aidpSvmsStkx+tS4wd+X3epqp4P4BoAdwYv\nbyuSjr5nq6Thmrx2bi6XcXaW/kqUj12hO16XWhTh3wugeczXJwXXVQRV3Rv83wVgDSpv9+HOLzdJ\nDf7virg/X6mknZvH21kaFfDYVdKO11GEfyOA+SIyT0SqAdwEYG0E/fgaEakPPoiBiNQDuBqVt/vw\nWgArgssrADwfYV+OUCk7N7t2lkbEj13F7XitqmX/B2AZRj/x/wTAz6Log6NfpwD4c/Dvw6j7BuBZ\njL4MTGP0s5HbAUwH0AZgB4BXADRWUN/+C8AWAO9jNGizI+rbpRh9Sf8+gM3Bv2VRP3ZGvyJ53HiG\nH5Gn+IEfkacYfiJPMfxEnmL4iTzF8BN5iuEn8hTDT+Qphp/IU/8Hi09KHGksOg4AAAAASUVORK5C\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpic8QdYNDkr",
        "colab_type": "text"
      },
      "source": [
        "Normalize the values for the neural network. Pixel values are all between 0 and 255."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1T1Tt87NOOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1dkVkF4NYMr",
        "colab_type": "text"
      },
      "source": [
        "## Building the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1EsKtsoNXZb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "1605495e-ff90-414e-ab18-3bb9e7ad757f"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "]\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0825 14:39:26.579864 140293323265920 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYUtEJ8MN8Wr",
        "colab_type": "text"
      },
      "source": [
        "**Sequential:** Defines a sequence of layers in the network\n",
        "**Flatten:** Turns the data into a 1-dimensional set\n",
        "**Dense:** Adds a fully connected layer\n",
        "**Relu:** If x>0 return x, else return 0. Only passes values 0 or greater to the next layer of the network.\n",
        "**Softmax:** Takes a set of values (i.e. probabilities) and picks the best one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ouX4-htOo1G",
        "colab_type": "text"
      },
      "source": [
        "## Building the Model\n",
        "Compile the model and fit it with the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEqyFPjGO0sY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ca55ddbb-a704-430a-89c6-0b48fa57f87b"
      },
      "source": [
        "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
        "             loss = 'sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 4s 72us/sample - loss: 0.4996 - acc: 0.8258\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.3754 - acc: 0.8644\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.3359 - acc: 0.8785\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.3123 - acc: 0.8860\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.2945 - acc: 0.8914\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f985c1da240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWuyqxWdPJ2T",
        "colab_type": "text"
      },
      "source": [
        "Try the model with unseen data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwciFX9UPLje",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8fccd2ec-12f8-4b78-88e6-f7fda0550830"
      },
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 31us/sample - loss: 0.3389 - acc: 0.8791\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3388712717294693, 0.8791]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VojZaVYTPipQ",
        "colab_type": "text"
      },
      "source": [
        "## Testing Model Alterations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHP_x8H7PnUU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "37e83041-163b-42e4-8df4-2a23f130a7a9"
      },
      "source": [
        "# Adding another layer\n",
        "model2 = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "]\n",
        ")\n",
        "model2.compile(optimizer=tf.train.AdamOptimizer(),\n",
        "             loss = 'sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "model2.fit(training_images, training_labels, epochs=5)\n",
        "model2.evaluate(test_images, test_labels)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.4743 - acc: 0.8307\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.3573 - acc: 0.8698\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.3217 - acc: 0.8819\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 112us/sample - loss: 0.2965 - acc: 0.8904\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.2769 - acc: 0.8968\n",
            "10000/10000 [==============================] - 1s 60us/sample - loss: 0.3354 - acc: 0.8801\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.335394571018219, 0.8801]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KNJLjLvQDoW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a51b6410-25e7-4a0a-cb9b-d315286514e2"
      },
      "source": [
        "# Adding more epochs\n",
        "# Adding another layer\n",
        "model3 = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "]\n",
        ")\n",
        "model3.compile(optimizer=tf.train.AdamOptimizer(),\n",
        "             loss = 'sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "model3.fit(training_images, training_labels, epochs=50)\n",
        "model3.evaluate(test_images, test_labels)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.5027 - acc: 0.8235\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.3789 - acc: 0.8625\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.3404 - acc: 0.8751\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.3152 - acc: 0.8843\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.2984 - acc: 0.8893\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.2847 - acc: 0.8934\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.2692 - acc: 0.8992\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.2584 - acc: 0.9032\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.2486 - acc: 0.9074\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.2399 - acc: 0.9101\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.2331 - acc: 0.9122\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.2247 - acc: 0.9143\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.2174 - acc: 0.9180\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.2103 - acc: 0.9217\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.2035 - acc: 0.9230\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.2002 - acc: 0.9246\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1939 - acc: 0.9275\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1880 - acc: 0.9287\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1859 - acc: 0.9297\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1784 - acc: 0.9337\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1762 - acc: 0.9327\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1700 - acc: 0.9363\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1664 - acc: 0.9377\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1626 - acc: 0.9388\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1606 - acc: 0.9397\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1550 - acc: 0.9416\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1507 - acc: 0.9427\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1495 - acc: 0.9445\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1453 - acc: 0.9452\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1425 - acc: 0.9453\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1387 - acc: 0.9473\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1369 - acc: 0.9476\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1349 - acc: 0.9494\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1308 - acc: 0.9508\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1294 - acc: 0.9506\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1261 - acc: 0.9524\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1219 - acc: 0.9538\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1211 - acc: 0.9545\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1204 - acc: 0.9546\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1154 - acc: 0.9571\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1158 - acc: 0.9568\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1117 - acc: 0.9570\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1106 - acc: 0.9573\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.1085 - acc: 0.9594\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1069 - acc: 0.9589\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 4s 65us/sample - loss: 0.1071 - acc: 0.9607\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 4s 64us/sample - loss: 0.1009 - acc: 0.9622\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 4s 67us/sample - loss: 0.1034 - acc: 0.9608\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 4s 68us/sample - loss: 0.0986 - acc: 0.9631\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 4s 67us/sample - loss: 0.0982 - acc: 0.9628\n",
            "10000/10000 [==============================] - 0s 37us/sample - loss: 0.4929 - acc: 0.8868\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.492916210308671, 0.8868]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC9TzQgqSn7f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "da23a363-356f-41b2-c8c5-5bd4dd154636"
      },
      "source": [
        "# Without normalization\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "model.evaluate(test_images, test_labels)\n",
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 7s 117us/sample - loss: 0.1981\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0811\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.0533\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.0379\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.0263\n",
            "10000/10000 [==============================] - 1s 62us/sample - loss: 0.0681\n",
            "[4.4411643e-09 1.0425157e-09 2.1901317e-07 9.8650389e-07 5.9627813e-13\n",
            " 2.9937991e-10 7.4538493e-14 9.9999821e-01 7.5430197e-11 6.2232141e-07]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvFzgRh5TCm5",
        "colab_type": "text"
      },
      "source": [
        "## Model callbacks\n",
        "Callbacks are a way to stop the training once you have reached a desired training loss or accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjTJXC3pTOxp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a7e1ab1-89ce-4015-8f83-1d402a6fdc48"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC5-4SCmTT2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('loss')<0.4):\n",
        "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
        "      self.model.stop_training=True\n",
        "\n",
        "callbacks = myCallback()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcV-StIATwvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAjrhM4MTyOf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5d09a319-1305-4b10-daf1-36f90fc192e6"
      },
      "source": [
        "# compile using callbacks\n",
        "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4720\n",
            "Epoch 2/5\n",
            "59808/60000 [============================>.] - ETA: 0s - loss: 0.3592\n",
            "Reached 60% accuracy so cancelling training!\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.3591\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9853b96898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}